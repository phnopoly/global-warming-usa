{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries needed\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from functools import reduce\n",
    "from statistics import median\n",
    "\n",
    "# Run previous ipynb files First then call MAIN_GRID\n",
    "%run extractData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = MAIN_GRID[2][1]\n",
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df0 = df0.rename(index=str, columns={'CSIRO - Adjusted sea level (inches)': \"CSIRO_ASLinches\", 'Year':'Year_Merge'})\n",
    "\n",
    "# Filter dataset to 1959-2015 for Year column and CSIRO_ASLinches\n",
    "df0_filter = df0.iloc[0:,[0,1]]\n",
    "df0_filter = (df0_filter.set_index(['Year_Merge']).loc[1959:2015]).reset_index()\n",
    "df0_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null/NA values\n",
    "df0_filter.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#towardsdatascience.com/handling-missing-values-with-pandas-b876bf6f008f\n",
    "#Filling 2 null values with mean of the records \n",
    "#df0_mean = df0_filter['CSIRO_ASLinches'].mean()\n",
    "#df0_filter['CSIRO_ASLinches'].fillna(df0_mean)\n",
    "#df0_mean #6.199642083854547, which is less than that of NOAA have recorded for these years\n",
    "#Alternatively missing values can be replaced with the values before or after them.\n",
    "df0_filter = df0_filter.fillna(axis=0, method = 'ffill', limit=2)\n",
    "\n",
    "# Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "# Calculate 57 year average\n",
    "avCSIRO_ASLinches_1959_2015 = np.mean(df0_filter['CSIRO_ASLinches']) \n",
    "df0_filter['Anamoly_CSIRO_ASLinches'] = df0_filter['CSIRO_ASLinches'] - avCSIRO_ASLinches_1959_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datahub.io/core/global-temp #useful reference data source\n",
    "\n",
    "df1 = MAIN_GRID[0][0]\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df1 = df1.rename(index=str, columns={'Rainfall - (MM)': \"Rnf_MM\", \" Year\": \"Year\", })\n",
    "\n",
    "# Filter data set to 1959-2015 and the columns Year and Rainfall (MM)\n",
    "df1_filter = df1.iloc[0:,[0,1]]\n",
    "df1_filter = (df1_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df1_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Year to proper format\n",
    "df1_filter['Year'] = pd.to_datetime(df1_filter['Year'], format='%Y')\n",
    "\n",
    "# Convert Year column to index\n",
    "df1_filter.set_index('Year',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative methods GroupBy and plot\n",
    "df1_filter_averagegrpby = df1_filter.groupby(pd.Grouper(freq='Y')).mean() #.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "\n",
    "avprecp_1959_2015 = np.mean(df1_filter_averagegrpby['Rnf_MM']) #Calculating 57 year average\n",
    "df1_filter_averagegrpby['Anamoly_RnfMM'] = df1_filter_averagegrpby['Rnf_MM'] - avprecp_1959_2015\n",
    "df1_filter_averagegrpby.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filter_averagegrpby.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index column\n",
    "#df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "df1_filter_averagegrpby.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Year to Year_Merge Column\n",
    "df1_filter_averagegrpby['Year_Merge'] = pd.DatetimeIndex(df1_filter_averagegrpby['Year']).year\n",
    "df1_filter_averagegrpby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = MAIN_GRID[0][1]\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df2 = df2.rename(index=str, columns={'Temperature - (Celsius)':\"Tmp_Cls\",\" Year\": \"Year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset to 1959-2015 and the columns Year and Rainfall (MM)\n",
    "df2_filter = df2.iloc[0:,[0,1]]\n",
    "df2_filter = (df2_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df2_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Year to proper format\n",
    "df2_filter['Year'] = pd.to_datetime(df2_filter['Year'], format='%Y')\n",
    "\n",
    "# Convert Year column to index\n",
    "df2_filter.set_index('Year',inplace=True)\n",
    "\n",
    "#df2_filter.info()\n",
    "df2_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/23859840/python-aggregate-by-month-and-calculate-average\n",
    "\n",
    "#Alternative methods GroupBy and plot\n",
    "df2_filter_averagegrpby = df2_filter.groupby(pd.Grouper(freq='Y')).mean()#.plot()\n",
    "df2_filter_averagegrpby.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "\n",
    "av_1959_2015 = np.mean(df2_filter_averagegrpby['Tmp_Cls']) #Calculating 57 years average\n",
    "df2_filter_averagegrpby['Anamoly_TmpCls'] =df2_filter_averagegrpby['Tmp_Cls'] - av_1959_2015\n",
    "df2_filter_averagegrpby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove index column\n",
    "# df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "df2_filter_averagegrpby.reset_index(level=0, inplace=True)\n",
    "\n",
    "# Extract Year to Year_Merge Column\n",
    "df2_filter_averagegrpby['Year_Merge'] = pd.DatetimeIndex(df1_filter_averagegrpby['Year']).year\n",
    "df2_filter_averagegrpby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = MAIN_GRID[2][0]\n",
    "\n",
    "df3.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking column names to identify white spaces\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df3 = df3.rename(index=str, columns={\"Year (negative values = BC)\": \"Year\", \"Mauna Loa, Hawaii\": \"MLHawai_CO2ppm\"})\n",
    "# Filter dataset to columns Year and ml_hawai\n",
    "df3_filter = df3.iloc[0:,[0,4]]\n",
    "\n",
    "# https://stackoverflow.com/questions/47444999/check-if-column-contains-type-string-object\n",
    "# Convert everything to numerical values \n",
    "df3_filter.loc[:, df3_filter.dtypes.eq('object')] = df3_filter.loc[:, df3_filter.dtypes.eq('object')].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df3_filter.info()\n",
    "\n",
    "#df3_filter.isnull().sum() #Checking if any null value exists.\n",
    "#df3_filter.isna().sum() #Checking if any na value exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1959-2015 and the columns Year and ml_hawai\n",
    "df3_filter = (df3_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df3_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking fro null/NA\n",
    "df3_filter.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Year to datatime format\n",
    "df3_filter['Year'] = pd.to_datetime(df3_filter['Year'], format='%Y')\n",
    "\n",
    "df3_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "avCO2ppm_1959_2015 = np.mean(df3_filter['MLHawai_CO2ppm']) #Calculating 57 year average\n",
    "df3_filter['Anamoly_CO2ppm'] =df3_filter['MLHawai_CO2ppm'] - avCO2ppm_1959_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract Year to Year_Merge Column\n",
    "df3_filter['Year_Merge'] = pd.DatetimeIndex(df3_filter['Year']).year\n",
    "df3_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes\n",
    "#\n",
    "# Merge dataframes and fill the values that don't exist in the lines of merged dataframe simply fill with required strings as\n",
    "\n",
    "\n",
    "df_tobe_merged = [df1_filter_averagegrpby,df2_filter_averagegrpby,df0_filter,df3_filter]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Year_Merge'], how='outer'), df_tobe_merged).fillna('void')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.info()\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns in df_merged\n",
    "df_merged_final = df_merged.iloc[0:,[3,1,2,5,6,7,8,10,11]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize statistics\n",
    " \n",
    "print('mean=%.3f median =%.3f stdv=%.3f' % (mean(df1_filter[\"Rnf_MM\"]), median(df1_filter[\"Rnf_MM\"]), std(df1_filter[\"Rnf_MM\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality Check - Hypothesis testing\n",
    "\n",
    "k2, p = stats.normaltest(df1_filter[\"Rnf_MM\"])\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p))\n",
    "\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")\n",
    "#The null hypothesis cannot be rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality Check - Hypothesis testing\n",
    "\n",
    "k2, p = stats.normaltest(df3_filter[\"MLHawai_CO2ppm\"])\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p))\n",
    "\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")\n",
    "#The null hypothesis cannot be rejected, since the dependent variable is normally distributed, we can perform Pearson's Correlation Test"
   ]
  }
 ]
}