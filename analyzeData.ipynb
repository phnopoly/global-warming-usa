{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "169d37cbee65175b98eaf955909079f32819eaf02ed7e8f38f83850ec4a19d58"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the librarys needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run previous ipynb files First then floowo grid in next step\n",
    "%run extractData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data files in Grid View\n",
    "MAIN_GRID[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datahub.io/core/global-temp #useful reference data source\n",
    "#load the data from repo to df\n",
    "import pandas as pd\n",
    "url ='https://raw.githubusercontent.com/zsaordenio/global-warming-usa/master/data/climateKnowledge/pr_1901_2016_USA.csv'\n",
    "df1 = pd.read_csv(url, error_bad_lines=False)\n",
    "df1.info() #checking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column name\n",
    "df1 = df1.rename(index=str, columns={'Rainfall - (MM)': \"Rnf_MM\", \" Year\": \"Year\", })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1990-2015 and the columns Year and Rainfall (MM)\n",
    "#start = 1990\n",
    "#end = 2015\n",
    "#l = list(df1_filter[' Year']) #ordered list of years\n",
    "#subl = l[l.index(start):l.index(end)+1] #list of years between the start and end\n",
    "#df1_filter[df1_filter[' Year'].isin(subl)] #filter dataset for list of names\n",
    "df1_filter = df1.iloc[0:,[0,1]]\n",
    "df1_filter = (df1_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df1_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Year to datatime format\n",
    "df1_filter['Year'] = pd.to_datetime(df1_filter['Year'], format='%Y')\n",
    "#Convert Year column  to index\n",
    "df1_filter.set_index('Year',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative methods GroupBy and plot\n",
    "df1_filter_averagegrpby = df1_filter.groupby(pd.Grouper(freq='Y')).mean() #.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "import numpy as np\n",
    "avprecp_1959_2015 = np.mean(df1_filter_averagegrpby['Rnf_MM']) #Calculating 26 year average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filter_averagegrpby['Anamoly_RnfMM'] = df1_filter_averagegrpby['Rnf_MM'] - avprecp_1959_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filter_averagegrpby "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filter_averagegrpby.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Remove index column\n",
    "#df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "df1_filter_averagegrpby.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Year to Year_Merge Column\n",
    "df1_filter_averagegrpby['Year_Merge'] = pd.DatetimeIndex(df1_filter_averagegrpby['Year']).year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filter_averagegrpby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data from repo to df\n",
    "import pandas as pd\n",
    "url1 ='https://github.com/zsaordenio/global-warming-usa/raw/master/data/climateKnowledge/tas_1901_2016_USA.csv'\n",
    "df2 = pd.read_csv(url1, error_bad_lines=False)\n",
    "df2.info() #checking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns\n",
    "#df2_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column name\n",
    "df2 = df2.rename(index=str, columns={'Temperature - (Celsius)':\"Tmp_Cls\",\" Year\": \"Year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1990-2015 and the columns Year and Rainfall (MM)\n",
    "df2_filter = df2.iloc[0:,[0,1]]\n",
    "df2_filter = (df2_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df2_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Year to datatime format\n",
    "#from io import StringIO\n",
    "#df2_average = pd.read_csv(StringIO(df2_filter),header=True,#parse_dates=['Year'],index_col='Year')\n",
    "df2_filter['Year'] = pd.to_datetime(df2_filter['Year'], format='%Y')\n",
    "\n",
    "#df2_filter['Year'] = pd.to_datetime(df2_filter['Year'])\n",
    "#df2_filter['Year'] = df2_filter['Year'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Year column  to index\n",
    "df2_filter.set_index('Year',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2_filter.info()\n",
    "df2_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/23859840/python-aggregate-by-month-and-calculate-average\n",
    "#df2_filter_average = df2_filter.resample('Y').mean()\n",
    "#Adding a year counter\n",
    "#df2_filter_average['cnt'] = range(len(df2_filter_average))\n",
    "#df2_filter_average\n",
    "#Alternative methods GroupBy and plot\n",
    "df2_filter_averagegrpby = df2_filter.groupby(pd.Grouper(freq='Y')).mean()#.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filter_averagegrpby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filter_averagegrpby.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "import numpy as np\n",
    "av_1959_2015 = np.mean(df2_filter_averagegrpby['Tmp_Cls']) #Calculating 26 year average\n",
    "df2_filter_averagegrpby['Anamoly_TmpCls'] =df2_filter_averagegrpby['Tmp_Cls'] - av_1959_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filter_averagegrpby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index column\n",
    "#df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "df2_filter_averagegrpby.reset_index(level=0, inplace=True)\n",
    "#Extract Year to Year_Merge Column\n",
    "df2_filter_averagegrpby['Year_Merge'] = pd.DatetimeIndex(df1_filter_averagegrpby['Year']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filter_averagegrpby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot anamoly vs Tmp_Cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data from repo to df\n",
    "import pandas as pd\n",
    "url2 ='https://github.com/zsaordenio/global-warming-usa/raw/master/data/epa/ghg-concentrations.csv'\n",
    "df3 = pd.read_csv(url2, error_bad_lines=False)\n",
    "df3.info() #checking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column name\n",
    "df3 = df3.rename(index=str, columns={\"Year (negative values = BC)\": \"Year\", \"Mauna Loa, Hawaii\": \"MLHawai_CO2ppm\"})\n",
    "#Filter data set to columns Year and ml_hawai\n",
    "df3_filter = df3.iloc[0:,[0,4]]\n",
    "#convert everything to numerical values #https://stackoverflow.com/questions/47444999/check-if-column-contains-type-string-object\n",
    "df3_filter.loc[:, df3_filter.dtypes.eq('object')] = df3_filter.loc[:, df3_filter.dtypes.eq('object')].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#checking the data types\n",
    "df3_filter.info()\n",
    "\n",
    "#df3_filter.isnull().sum() #Checking if any null value exists.\n",
    "#df3_filter.isna().sum() #Checking if any na value exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1959-2015 and the columns Year and ml_hawai\n",
    "df3_filter = (df3_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df3_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter.isna().sum() #Checking if any null value exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting year to int64\n",
    "#df3_filter['Year'] = df3_filter['Year'].astype(np.int64) #casting float64 to int64\n",
    "#Convert Year to datatime format\n",
    "df3_filter['Year'] = pd.to_datetime(df3_filter['Year'], format='%Y')\n",
    "#Convert Year column  to index\n",
    "#df3_filter.set_index('Year',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "import numpy as np\n",
    "avCO2ppm_1959_2015 = np.mean(df3_filter['MLHawai_CO2ppm']) #Calculating 26 year average\n",
    "df3_filter['Anamoly_CO2ppm'] =df3_filter['MLHawai_CO2ppm'] - avCO2ppm_1959_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index column\n",
    "#df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "#df1_filter_averagegrpby.reset_index(level=0, inplace=True)\n",
    "#Extract Year to Year_Merge Column\n",
    "df3_filter['Year_Merge'] = pd.DatetimeIndex(df3_filter['Year']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes and fill the values that don't exist in the lines of merged dataframe simply fill with required strings as #https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes#:~:text=Just%20simply%20merge%20with%20DATE,to%20get%20all%20the%20data).&text=Now%2C%20basically%20load%20all%20the,using%20merge%20or%20reduce%20function.&text=Note%3A%20you%20can%20add%20as,frames%20inside%20the%20above%20list.\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "df_tobe_merged = [df1_filter_averagegrpby,df2_filter_averagegrpby, df3_filter]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Year_Merge'], how='outer'), df_tobe_merged).fillna('void')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.info()\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearrange the dataframe merged\n",
    "df_merged_final = df_merged.iloc[0:,[3,1,2,5,6,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize\n",
    "from statistics import median \n",
    "print('mean=%.3f median =%.3f stdv=%.3f' % (mean(df1_filter[\"Rnf_MM\"]), median(df1_filter[\"Rnf_MM\"]), std(df1_filter[\"Rnf_MM\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram plot #Normality Check\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "alt.Chart(df1_filter).mark_bar().encode(\n",
    "    alt.X(\"Rnf_MM:Q\",\n",
    "          bin= True), #alt.BinParams(maxbins=100)\n",
    "    y='count(*):Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality Check # Hypothesis testing\n",
    "from scipy import stats\n",
    "k2, p = stats.normaltest(df1_filter[\"Rnf_MM\"])\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p))\n",
    "\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")\n",
    "#The null hypothesis can be rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot # Distribution\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "\n",
    "alt.Chart(df_merged).mark_circle().encode(\n",
    "    alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "    alt.Y(alt.repeat(\"row\"), type='quantitative'),\n",
    "    color='Year_Merge:O'\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=150\n",
    ").repeat(\n",
    "    column=['Rnf_MM','Tmp_Cls','MLHawai_CO2ppm'],\n",
    "    row=['MLHawai_CO2ppm','Tmp_Cls','Rnf_MM']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot # Distribution\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "alt.Chart(df_merged).mark_circle().encode(\n",
    "    alt.X('Year_Merge:O', scale=alt.Scale(zero=False)),\n",
    "    alt.Y('Tmp_Cls:Q', scale=alt.Scale(zero=False, padding=1)),\n",
    "    color='Anamoly_TmpCls:Q',\n",
    "    size='MLHawai_CO2ppm:Q'\n",
    ")\n"
   ]
  }
 ]
}