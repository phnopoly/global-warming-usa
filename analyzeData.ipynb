{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the librarys needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run previous ipynb files First then call MAIN_GRID\n",
    "%run extractData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_GRID[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = MAIN_GRID[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info() #checking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0.columns\n",
    "df0 = df0.rename(index=str, columns={'CSIRO - Adjusted sea level (inches)': \"CSIRO_ASLinches\", 'Year':'Year_Merge'}) #Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1959-2015 and the columns Year and CSIRO_ASLinches\n",
    "df0_filter = df0.iloc[0:,[0,1]]\n",
    "df0_filter = (df0_filter.set_index(['Year_Merge']).loc[1959:2015]).reset_index()\n",
    "df0_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null/na valfues if any exists\n",
    "df0_filter.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#towardsdatascience.com/handling-missing-values-with-pandas-b876bf6f008f\n",
    "#Filling 2 null values with mean of the records \n",
    "#df0_mean = df0_filter['CSIRO_ASLinches'].mean()\n",
    "#df0_filter['CSIRO_ASLinches'].fillna(df0_mean)\n",
    "#df0_mean #6.199642083854547, which is less than that of NOAA have recorded for these years\n",
    "#Alternatively missing values can be replaced with the values before or after them.\n",
    "df0_filter = df0_filter.fillna(axis=0, method = 'ffill', limit=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "avCSIRO_ASLinches_1959_2015 = np.mean(df0_filter['CSIRO_ASLinches']) #Calculating 57 year average\n",
    "df0_filter['Anamoly_CSIRO_ASLinches'] = df0_filter['CSIRO_ASLinches'] - avCSIRO_ASLinches_1959_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datahub.io/core/global-temp #useful reference data source\n",
    "\n",
    "df1 = MAIN_GRID[0][0]\n",
    "df1.info() #checking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns #checking the column names if any whitespaces exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column name\n",
    "df1 = df1.rename(index=str, columns={'Rainfall - (MM)': \"Rnf_MM\", \" Year\": \"Year\", })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1959-2015 and the columns Year and Rainfall (MM)\n",
    "df1_filter = df1.iloc[0:,[0,1]]\n",
    "df1_filter = (df1_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df1_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Year to datatime format\n",
    "df1_filter['Year'] = pd.to_datetime(df1_filter['Year'], format='%Y')\n",
    "#Convert Year column  to index\n",
    "df1_filter.set_index('Year',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative methods GroupBy and plot\n",
    "df1_filter_averagegrpby = df1_filter.groupby(pd.Grouper(freq='Y')).mean() #.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "\n",
    "avprecp_1959_2015 = np.mean(df1_filter_averagegrpby['Rnf_MM']) #Calculating 57 year average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filter_averagegrpby['Anamoly_RnfMM'] = df1_filter_averagegrpby['Rnf_MM'] - avprecp_1959_2015\n",
    "df1_filter_averagegrpby.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filter_averagegrpby.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index column\n",
    "#df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "df1_filter_averagegrpby.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Year to Year_Merge Column\n",
    "df1_filter_averagegrpby['Year_Merge'] = pd.DatetimeIndex(df1_filter_averagegrpby['Year']).year\n",
    "df1_filter_averagegrpby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = MAIN_GRID[0][1]\n",
    "df2.info() #checking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns\n",
    "#df2_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column name\n",
    "df2 = df2.rename(index=str, columns={'Temperature - (Celsius)':\"Tmp_Cls\",\" Year\": \"Year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1959-2015 and the columns Year and Rainfall (MM)\n",
    "df2_filter = df2.iloc[0:,[0,1]]\n",
    "df2_filter = (df2_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df2_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Year to datatime format\n",
    "#from io import StringIO\n",
    "#df2_average = pd.read_csv(StringIO(df2_filter),header=True,#parse_dates=['Year'],index_col='Year')\n",
    "df2_filter['Year'] = pd.to_datetime(df2_filter['Year'], format='%Y')\n",
    "\n",
    "#df2_filter['Year'] = pd.to_datetime(df2_filter['Year'])\n",
    "#df2_filter['Year'] = df2_filter['Year'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Year column  to index\n",
    "df2_filter.set_index('Year',inplace=True)\n",
    "#df2_filter.info()\n",
    "df2_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/23859840/python-aggregate-by-month-and-calculate-average\n",
    "#df2_filter_average = df2_filter.resample('Y').mean()\n",
    "#Adding a year counter\n",
    "#df2_filter_average['cnt'] = range(len(df2_filter_average))\n",
    "#df2_filter_average\n",
    "#Alternative methods GroupBy and plot\n",
    "df2_filter_averagegrpby = df2_filter.groupby(pd.Grouper(freq='Y')).mean()#.plot()\n",
    "df2_filter_averagegrpby.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "import numpy as np\n",
    "av_1959_2015 = np.mean(df2_filter_averagegrpby['Tmp_Cls']) #Calculating 57 years average\n",
    "df2_filter_averagegrpby['Anamoly_TmpCls'] =df2_filter_averagegrpby['Tmp_Cls'] - av_1959_2015\n",
    "df2_filter_averagegrpby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index column\n",
    "#df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "df2_filter_averagegrpby.reset_index(level=0, inplace=True)\n",
    "#Extract Year to Year_Merge Column\n",
    "df2_filter_averagegrpby['Year_Merge'] = pd.DatetimeIndex(df1_filter_averagegrpby['Year']).year\n",
    "df2_filter_averagegrpby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = MAIN_GRID[2][0]\n",
    "df3.info() #checking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking the column names to identify white spaces if any\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column name\n",
    "df3 = df3.rename(index=str, columns={\"Year (negative values = BC)\": \"Year\", \"Mauna Loa, Hawaii\": \"MLHawai_CO2ppm\"})\n",
    "#Filter data set to columns Year and ml_hawai\n",
    "df3_filter = df3.iloc[0:,[0,4]]\n",
    "#convert everything to numerical values #https://stackoverflow.com/questions/47444999/check-if-column-contains-type-string-object\n",
    "df3_filter.loc[:, df3_filter.dtypes.eq('object')] = df3_filter.loc[:, df3_filter.dtypes.eq('object')].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#checking the data types\n",
    "df3_filter.info()\n",
    "\n",
    "#df3_filter.isnull().sum() #Checking if any null value exists.\n",
    "#df3_filter.isna().sum() #Checking if any na value exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data set to 1959-2015 and the columns Year and ml_hawai\n",
    "df3_filter = (df3_filter.set_index(['Year']).loc[1959:2015]).reset_index()\n",
    "df3_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if any null value exists.\n",
    "df3_filter.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting year to int64\n",
    "#df3_filter['Year'] = df3_filter['Year'].astype(np.int64) #casting float64 to int64\n",
    "#Convert Year to datatime format\n",
    "df3_filter['Year'] = pd.to_datetime(df3_filter['Year'], format='%Y')\n",
    "#Convert Year column  to index\n",
    "#df3_filter.set_index('Year',inplace=True)\n",
    "df3_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anamoly Detection #https://help.ceda.ac.uk/article/4728-cru-data-python-example\n",
    "avCO2ppm_1959_2015 = np.mean(df3_filter['MLHawai_CO2ppm']) #Calculating 57 year average\n",
    "df3_filter['Anamoly_CO2ppm'] =df3_filter['MLHawai_CO2ppm'] - avCO2ppm_1959_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index column\n",
    "#df1_filter_averagegrpby.index #removes time portion from time stamp\n",
    "#df1_filter_averagegrpby.reset_index(level=0, inplace=True)\n",
    "#Extract Year to Year_Merge Column\n",
    "df3_filter['Year_Merge'] = pd.DatetimeIndex(df3_filter['Year']).year\n",
    "df3_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes and fill the values that don't exist in the lines of merged dataframe simply fill with required strings as #https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes#:~:text=Just%20simply%20merge%20with%20DATE,to%20get%20all%20the%20data).&text=Now%2C%20basically%20load%20all%20the,using%20merge%20or%20reduce%20function.&text=Note%3A%20you%20can%20add%20as,frames%20inside%20the%20above%20list.\n",
    "\n",
    "from functools import reduce\n",
    "df_tobe_merged = [df1_filter_averagegrpby,df2_filter_averagegrpby,df0_filter,df3_filter]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Year_Merge'], how='outer'), df_tobe_merged).fillna('void')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.info()\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearrange the columns to the dataframe merged\n",
    "df_merged_final = df_merged.iloc[0:,[3,1,2,5,6,7,8,10,11]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize\n",
    "from statistics import median \n",
    "print('mean=%.3f median =%.3f stdv=%.3f' % (mean(df1_filter[\"Rnf_MM\"]), median(df1_filter[\"Rnf_MM\"]), std(df1_filter[\"Rnf_MM\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality Check # Hypothesis testing\n",
    "from scipy import stats\n",
    "k2, p = stats.normaltest(df1_filter[\"Rnf_MM\"])\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p))\n",
    "\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")\n",
    "#The null hypothesis cannot be rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality Check # Hypothesis testing\n",
    "from scipy import stats\n",
    "k2, p = stats.normaltest(df3_filter[\"MLHawai_CO2ppm\"])\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p))\n",
    "\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")\n",
    "#The null hypothesis cannot be rejected, since the dependent variable is normally distributed, we can perform Pearson's Correlation Test"
   ]
  }
 ]
}